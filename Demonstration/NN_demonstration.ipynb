{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " %reload_ext tensorboard\n",
    "from tensorflow.keras import Model\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 128\n",
    "LEARNING_RATE = 0.05\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_dir = Path('./data/prepared')\n",
    "logs_path = Path('./data/logs')\n",
    "if logs_path.exists():\n",
    "  shutil.rmtree(logs_path)\n",
    "logs_path.mkdir(parents=True)\n",
    "\n",
    "X_train_name = input_dir / 'X_train.csv'\n",
    "y_train_name = input_dir / 'y_train.csv'\n",
    "X_test_name = input_dir / 'X_test.csv'\n",
    "y_test_name = input_dir / 'y_test.csv'\n",
    "\n",
    "X_train = pd.read_csv(X_train_name)\n",
    "y_train = pd.read_csv(y_train_name)\n",
    "X_test = pd.read_csv(X_test_name)\n",
    "y_test = pd.read_csv(y_test_name)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_train, y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(436, 8)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<BatchDataset element_spec=(TensorSpec(shape=(None, 8), dtype=tf.int64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SomeModel(Model):\n",
    "  def __init__(self, neurons_cnt=128):\n",
    "    super(SomeModel, self).__init__()\n",
    "\n",
    "    self.d_in = Dense(8, activation='relu')\n",
    "    self.d1 = Dense(neurons_cnt, activation='relu')\n",
    "    self.d2 = Dense(neurons_cnt, activation='relu')\n",
    "    self.d_out = Dense(1)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.d_in(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = SomeModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.MeanAbsoluteError(name='train_mae')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.MeanAbsoluteError(name='test_mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_vector, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(input_vector, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(input_vector, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(input_vector, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1836.6314697265625, Accuracy: 26.772335052490234, Test Loss: 186.45669555664062, Test MAE: 13.622997283935547\n",
      "Epoch 2, Loss: 63.46037673950195, Accuracy: 6.925711631774902, Test Loss: 32.88878631591797, Test MAE: 5.6812944412231445\n",
      "Epoch 3, Loss: 20.731775283813477, Accuracy: 3.4891653060913086, Test Loss: 25.660781860351562, Test MAE: 4.990583419799805\n",
      "Epoch 4, Loss: 25.706134796142578, Accuracy: 4.84944486618042, Test Loss: 12.958181381225586, Test MAE: 3.509610176086426\n",
      "Epoch 5, Loss: 16.78478240966797, Accuracy: 3.942241668701172, Test Loss: 11.663522720336914, Test MAE: 3.307110071182251\n",
      "Epoch 6, Loss: 9.935452461242676, Accuracy: 3.0274620056152344, Test Loss: 8.045533180236816, Test MAE: 2.7192118167877197\n",
      "Epoch 7, Loss: 8.748234748840332, Accuracy: 2.8353326320648193, Test Loss: 10.110368728637695, Test MAE: 3.067755937576294\n",
      "Epoch 8, Loss: 5.244282245635986, Accuracy: 2.1211204528808594, Test Loss: 5.171787738800049, Test MAE: 2.124237060546875\n",
      "Epoch 9, Loss: 5.398852825164795, Accuracy: 2.196573495864868, Test Loss: 5.732843399047852, Test MAE: 2.2784998416900635\n",
      "Epoch 10, Loss: 4.616725444793701, Accuracy: 2.0201196670532227, Test Loss: 2.8430211544036865, Test MAE: 1.476998209953308\n",
      "Epoch 11, Loss: 2.130341053009033, Accuracy: 1.2874232530593872, Test Loss: 1.972387433052063, Test MAE: 1.2989774942398071\n",
      "Epoch 12, Loss: 1.3353432416915894, Accuracy: 0.9571381211280823, Test Loss: 2.771125555038452, Test MAE: 1.4527084827423096\n",
      "Epoch 13, Loss: 2.704974412918091, Accuracy: 1.4860237836837769, Test Loss: 2.723771572113037, Test MAE: 1.5428885221481323\n",
      "Epoch 14, Loss: 1.3054454326629639, Accuracy: 0.9550907015800476, Test Loss: 2.286309242248535, Test MAE: 1.2765895128250122\n",
      "Epoch 15, Loss: 1.4090497493743896, Accuracy: 0.9940528273582458, Test Loss: 0.790408730506897, Test MAE: 0.7269793748855591\n",
      "Epoch 16, Loss: 0.6500787138938904, Accuracy: 0.628126859664917, Test Loss: 1.1738252639770508, Test MAE: 0.7597753405570984\n",
      "Epoch 17, Loss: 1.0424630641937256, Accuracy: 0.7993995547294617, Test Loss: 2.107046604156494, Test MAE: 1.346056342124939\n",
      "Epoch 18, Loss: 1.3130210638046265, Accuracy: 0.9584523439407349, Test Loss: 1.3721704483032227, Test MAE: 0.8675644397735596\n",
      "Epoch 19, Loss: 0.8304492831230164, Accuracy: 0.7000865936279297, Test Loss: 0.6906641721725464, Test MAE: 0.5893375277519226\n",
      "Epoch 20, Loss: 0.631703794002533, Accuracy: 0.5960314869880676, Test Loss: 0.7957785129547119, Test MAE: 0.7311856746673584\n",
      "Epoch 21, Loss: 0.7021371722221375, Accuracy: 0.6533589959144592, Test Loss: 0.9682188630104065, Test MAE: 0.6475241780281067\n",
      "Epoch 22, Loss: 0.98713618516922, Accuracy: 0.79564368724823, Test Loss: 0.9259404540061951, Test MAE: 0.8262918591499329\n",
      "Epoch 23, Loss: 1.4744230508804321, Accuracy: 1.0272549390792847, Test Loss: 1.7315442562103271, Test MAE: 1.044687032699585\n",
      "Epoch 24, Loss: 1.9718115329742432, Accuracy: 1.2234400510787964, Test Loss: 1.1435742378234863, Test MAE: 0.953572154045105\n",
      "Epoch 25, Loss: 0.760363757610321, Accuracy: 0.6908845901489258, Test Loss: 0.7138887047767639, Test MAE: 0.5731282234191895\n",
      "Epoch 26, Loss: 0.6847077012062073, Accuracy: 0.6242378950119019, Test Loss: 0.7863872051239014, Test MAE: 0.7237564921379089\n",
      "Epoch 27, Loss: 0.6747140884399414, Accuracy: 0.6174172759056091, Test Loss: 0.7393779754638672, Test MAE: 0.6828292608261108\n",
      "Epoch 28, Loss: 0.6176643371582031, Accuracy: 0.6041713953018188, Test Loss: 0.7396010756492615, Test MAE: 0.5701034665107727\n",
      "Epoch 29, Loss: 0.5752679705619812, Accuracy: 0.5676864385604858, Test Loss: 0.690637469291687, Test MAE: 0.5893913507461548\n",
      "Epoch 30, Loss: 0.5707308650016785, Accuracy: 0.5654627680778503, Test Loss: 0.6997810006141663, Test MAE: 0.5795047879219055\n",
      "Epoch 31, Loss: 0.5994729995727539, Accuracy: 0.5820490717887878, Test Loss: 0.717850923538208, Test MAE: 0.660045325756073\n",
      "Epoch 32, Loss: 0.6730853915214539, Accuracy: 0.6269007921218872, Test Loss: 0.8028662204742432, Test MAE: 0.5793725252151489\n",
      "Epoch 33, Loss: 0.6175500750541687, Accuracy: 0.5964399576187134, Test Loss: 0.7607724070549011, Test MAE: 0.5706783533096313\n",
      "Epoch 34, Loss: 0.6679426431655884, Accuracy: 0.600655734539032, Test Loss: 0.9442535042762756, Test MAE: 0.8383694291114807\n",
      "Epoch 35, Loss: 1.024699091911316, Accuracy: 0.8039506077766418, Test Loss: 1.3196942806243896, Test MAE: 0.8394848108291626\n",
      "Epoch 36, Loss: 0.6763361692428589, Accuracy: 0.6323489546775818, Test Loss: 0.6897929310798645, Test MAE: 0.6120441555976868\n",
      "Epoch 37, Loss: 0.5867418050765991, Accuracy: 0.5777669548988342, Test Loss: 0.7460603713989258, Test MAE: 0.6890137195587158\n",
      "Epoch 38, Loss: 0.6459373831748962, Accuracy: 0.6102352142333984, Test Loss: 0.8780553340911865, Test MAE: 0.792998731136322\n",
      "Epoch 39, Loss: 0.903102695941925, Accuracy: 0.7552165985107422, Test Loss: 1.4193509817123413, Test MAE: 0.8923288583755493\n",
      "Epoch 40, Loss: 1.3259057998657227, Accuracy: 0.9614186882972717, Test Loss: 0.8438984751701355, Test MAE: 0.7678835988044739\n",
      "Epoch 41, Loss: 0.6616278290748596, Accuracy: 0.6293074488639832, Test Loss: 0.7144237756729126, Test MAE: 0.572938859462738\n",
      "Epoch 42, Loss: 0.6513460874557495, Accuracy: 0.6064695715904236, Test Loss: 0.974460244178772, Test MAE: 0.650887131690979\n",
      "Epoch 43, Loss: 0.7298740148544312, Accuracy: 0.6477842330932617, Test Loss: 1.3240256309509277, Test MAE: 0.8418198227882385\n",
      "Epoch 44, Loss: 1.0616414546966553, Accuracy: 0.8262631893157959, Test Loss: 0.9201409816741943, Test MAE: 0.8223708868026733\n",
      "Epoch 45, Loss: 0.6913047432899475, Accuracy: 0.6654518246650696, Test Loss: 0.9140933752059937, Test MAE: 0.6224749088287354\n",
      "Epoch 46, Loss: 0.5880705714225769, Accuracy: 0.5769530534744263, Test Loss: 0.7972016930580139, Test MAE: 0.5778103470802307\n",
      "Epoch 47, Loss: 0.7232467532157898, Accuracy: 0.6453109979629517, Test Loss: 0.7079268097877502, Test MAE: 0.6472185254096985\n",
      "Epoch 48, Loss: 0.5762352347373962, Accuracy: 0.5705358982086182, Test Loss: 0.7219415903091431, Test MAE: 0.6647728085517883\n",
      "Epoch 49, Loss: 0.8270701169967651, Accuracy: 0.7076213955879211, Test Loss: 1.30820631980896, Test MAE: 0.8332964777946472\n",
      "Epoch 50, Loss: 0.8952217698097229, Accuracy: 0.7520875334739685, Test Loss: 1.0993963479995728, Test MAE: 0.9304686784744263\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = logs_path / 'gradient_tape' / current_time / 'train'\n",
    "train_log_dir.mkdir(exist_ok=True, parents=True)\n",
    "test_log_dir = logs_path / 'gradient_tape' / current_time / 'test'\n",
    "test_log_dir.mkdir(exist_ok=True, parents=True)\n",
    "train_summary_writer = tf.summary.create_file_writer(str(train_log_dir))\n",
    "test_summary_writer = tf.summary.create_file_writer(str(test_log_dir))\n",
    "\n",
    "logdir=logs_path / \"fit\" / datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir.mkdir(exist_ok=True, parents=True)\n",
    "fit_summary_writer = tf.summary.create_file_writer(str(logdir))\n",
    "\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  for (x_train, y_train) in train_ds:\n",
    "\n",
    "    with fit_summary_writer.as_default():\n",
    "      train_step(x_train, y_train)\n",
    "\n",
    "\n",
    "  with train_summary_writer.as_default():\n",
    "    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "    tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "  for (x_test, y_test) in test_ds:\n",
    "    test_step(x_test, y_test)\n",
    "\n",
    "  with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "    tf.summary.scalar('mae', test_accuracy.result(), step=epoch)\n",
    "\n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test MAE: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result(),\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()))\n",
    "\n",
    "  # Reset metrics every epoch\n",
    "  train_loss.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "with fit_summary_writer.as_default():\n",
    "  tf.summary.trace_export(\n",
    "      name=\"my_func_trace\",\n",
    "      step=0,\n",
    "      profiler_outdir=logdir\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/mymodel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./data/models/mymodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model('./data/models/mymodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<keras.saving.legacy.saved_model.load.SomeModel at 0x25f94bab4c0>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<__main__.SomeModel at 0x25f94baabc0>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check:\n",
    "import numpy as np\n",
    "np.testing.assert_allclose(\n",
    "    model.predict(X_test), loaded_model.predict(X_test)\n",
    ")\n",
    "%tensorboard --logdir ./data/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./data/logs/gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}